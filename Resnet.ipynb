{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1khlJ9pUQ2c1GxBLjav26oJHMxwPlvLy4","authorship_tag":"ABX9TyPNG/74CsDqzpNH8gB2GpNm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install split-folders"],"metadata":{"id":"jrESv5WTS_eX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714498009453,"user_tz":-330,"elapsed":10363,"user":{"displayName":"Sanjay P","userId":"03374728241233417550"}},"outputId":"07252949-0e88-4543-f7a6-d8a0e00f6da8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting split-folders\n","  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n","Installing collected packages: split-folders\n","Successfully installed split-folders-0.5.1\n"]}]},{"cell_type":"code","source":["input_folder = '/content/drive/MyDrive/Trimmed_AID'"],"metadata":{"id":"S0YH5PQjS_bu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import splitfolders as sf"],"metadata":{"id":"V8dnQb2AS_ZX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sf.ratio(input_folder,output = '/content/drive/MyDrive/Trimmed_AID_dataset',seed=42,ratio=(.7,.2,.1),group_prefix=None)"],"metadata":{"id":"0sehR4K4REqm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714498117050,"user_tz":-330,"elapsed":86293,"user":{"displayName":"Sanjay P","userId":"03374728241233417550"}},"outputId":"924f391d-2174-45aa-d2a5-386b5d81b5ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Copying files: 3369 files [01:24, 39.74 files/s]\n"]}]},{"cell_type":"markdown","source":["Start\n"],"metadata":{"id":"aosRXEKq-Zk3"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RW3sDNnnHM64","executionInfo":{"status":"ok","timestamp":1715528011522,"user_tz":-330,"elapsed":32017,"user":{"displayName":"Sanjay P","userId":"03374728241233417550"}},"outputId":"79643d92-e824-4da0-c3db-e5fc2c07f398"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras import Sequential\n","from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout\n"],"metadata":{"id":"47q7XWU6bH2c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_ds = keras.utils.image_dataset_from_directory(\n","    directory='/content/drive/MyDrive/Trimmed_AID_dataset/train',\n","    labels='inferred',\n","    label_mode='categorical',\n","    batch_size=32,\n","    image_size=(256, 256))\n","validation_ds = keras.utils.image_dataset_from_directory(\n","    directory='/content/drive/MyDrive/Trimmed_AID_dataset/val',\n","    labels='inferred',\n","    label_mode='categorical',\n","    batch_size=32,\n","    image_size=(256, 256))\n","test_ds = keras.utils.image_dataset_from_directory(\n","    directory='/content/drive/MyDrive/Trimmed_AID_dataset/test',\n","    labels='inferred',\n","    label_mode='categorical',\n","    batch_size=32,\n","    image_size=(256, 256))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uMgnsBSEbHlE","executionInfo":{"status":"ok","timestamp":1715528056286,"user_tz":-330,"elapsed":21450,"user":{"displayName":"Sanjay P","userId":"03374728241233417550"}},"outputId":"e6a95f8f-dbcd-4601-b8c9-7c6b3538f512"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1346 files belonging to 30 classes.\n","Found 672 files belonging to 30 classes.\n","Found 1351 files belonging to 30 classes.\n"]}]},{"cell_type":"code","source":["classes = ['Airport', 'BareLand', 'BaseballField', 'Beach', 'Bridge', 'Center', 'Church', 'Commercial', 'DenseResidential', 'Desert', 'Farmland', 'Forest', 'Industrial', 'Meadow', 'MediumResidential', 'Mountain', 'Park', 'Parking', 'Playground', 'Pond', 'Port', 'RailwayStation', 'Resort', 'River', 'School', 'SparseResidential', 'Square', 'Stadium', 'StorageTanks', 'Viaduct']\n","num_classes = len(classes)"],"metadata":{"id":"ZDia13pK6Cpe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ResNet"],"metadata":{"id":"kg2Qsw3p8iQn"}},{"cell_type":"code","source":["from keras.applications import ResNet50"],"metadata":{"id":"iexoIOOK9Wu6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Build ResNet model\n","resnet_model = Sequential()\n","resnet_model.add(ResNet50(include_top=False, weights='imagenet', input_shape=(256, 256, 3)))\n","resnet_model.add(Flatten())\n","resnet_model.add(Dense(256, activation='relu'))\n","resnet_model.add(Dropout(0.5))\n","resnet_model.add(Dense(num_classes, activation='softmax'))\n","\n","# Compile and fit ResNet model\n","resnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","resnet_model.fit(train_ds, epochs=10, validation_data=validation_ds)"],"metadata":{"id":"vJTDkopM8fij","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715529173230,"user_tz":-330,"elapsed":1076176,"user":{"displayName":"Sanjay P","userId":"03374728241233417550"}},"outputId":"4dc53b6d-2481-45ff-f771-73e68ce41ab1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94765736/94765736 [==============================] - 4s 0us/step\n","Epoch 1/10\n","43/43 [==============================] - 740s 14s/step - loss: 7.9304 - accuracy: 0.1738 - val_loss: 248244.4531 - val_accuracy: 0.0298\n","Epoch 2/10\n","43/43 [==============================] - 26s 557ms/step - loss: 2.8830 - accuracy: 0.2689 - val_loss: 40.8276 - val_accuracy: 0.0565\n","Epoch 3/10\n","43/43 [==============================] - 29s 632ms/step - loss: 2.3111 - accuracy: 0.3945 - val_loss: 41.1628 - val_accuracy: 0.0565\n","Epoch 4/10\n","43/43 [==============================] - 25s 551ms/step - loss: 1.9117 - accuracy: 0.4926 - val_loss: 11.3198 - val_accuracy: 0.0565\n","Epoch 5/10\n","43/43 [==============================] - 29s 631ms/step - loss: 1.7596 - accuracy: 0.5817 - val_loss: 33.1067 - val_accuracy: 0.0298\n","Epoch 6/10\n","43/43 [==============================] - 29s 636ms/step - loss: 1.3490 - accuracy: 0.6657 - val_loss: 12.3297 - val_accuracy: 0.0298\n","Epoch 7/10\n","43/43 [==============================] - 25s 538ms/step - loss: 1.2314 - accuracy: 0.6887 - val_loss: 9.5030 - val_accuracy: 0.0327\n","Epoch 8/10\n","43/43 [==============================] - 29s 638ms/step - loss: 1.1150 - accuracy: 0.6984 - val_loss: 4.7753 - val_accuracy: 0.0565\n","Epoch 9/10\n","43/43 [==============================] - 25s 551ms/step - loss: 1.4747 - accuracy: 0.6627 - val_loss: 14.4199 - val_accuracy: 0.0565\n","Epoch 10/10\n","43/43 [==============================] - 26s 557ms/step - loss: 1.2116 - accuracy: 0.6969 - val_loss: 24.7633 - val_accuracy: 0.0298\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7a43d42d8790>"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["there seem to be some issues with the validation loss and accuracy. The validation loss is extremely high, which indicates that the model might not be generalizing well to unseen data. Additionally, the validation accuracy is very low, which further confirms the poor performance on the validation set."],"metadata":{"id":"7hT1eQhkgaAK"}},{"cell_type":"code","source":["from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"],"metadata":{"id":"RbYKl7lCgt4z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Regularization"],"metadata":{"id":"IMiy4y7nkX3O"}},{"cell_type":"markdown","source":["let's add a few more regularization techniques to our model. Apart from dropout, we can include batch normalization and L2 regularization.\n","\n","We added an L2 regularization term to the Dense layer with a regularization strength of 0.001. This helps prevent overfitting by penalizing large weights.\n","\n","We included a BatchNormalization layer after the Dense layer. Batch normalization normalizes the activations of the previous layer, which can help stabilize and speed up the training process."],"metadata":{"id":"6OjkN6pqjwzU"}},{"cell_type":"code","source":["# Build ResNet model\n","resnet_model = Sequential()\n","resnet_model.add(ResNet50(include_top=False, weights='imagenet', input_shape=(256, 256, 3)))\n","resnet_model.add(Flatten())\n","resnet_model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001)))  # L2 regularization\n","resnet_model.add(BatchNormalization())  # Batch normalization layer\n","resnet_model.add(Dropout(0.5))  # Dropout layer\n","resnet_model.add(Dense(num_classes, activation='softmax'))\n","\n","\n","# Define callbacks\n","early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)\n","\n","# Compile and fit ResNet model with callbacks\n","resnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","resnet_model.fit(train_ds, epochs=10, validation_data=validation_ds, callbacks=[early_stopping, checkpoint])"],"metadata":{"id":"BnnYfpllgswN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715530324919,"user_tz":-330,"elapsed":263762,"user":{"displayName":"Sanjay P","userId":"03374728241233417550"}},"outputId":"c0566ae2-2455-4c30-d38a-1f3ca3302fd8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","43/43 [==============================] - 66s 819ms/step - loss: 3.7201 - accuracy: 0.3596 - val_loss: 868.4080 - val_accuracy: 0.0298\n","Epoch 2/10\n","43/43 [==============================] - 35s 763ms/step - loss: 2.7750 - accuracy: 0.6315 - val_loss: 20.1528 - val_accuracy: 0.0565\n","Epoch 3/10\n","43/43 [==============================] - 29s 639ms/step - loss: 2.1139 - accuracy: 0.8046 - val_loss: 49.3502 - val_accuracy: 0.0298\n","Epoch 4/10\n","43/43 [==============================] - 29s 646ms/step - loss: 1.9483 - accuracy: 0.8432 - val_loss: 9.2003 - val_accuracy: 0.0298\n","Epoch 5/10\n","43/43 [==============================] - 29s 634ms/step - loss: 1.7723 - accuracy: 0.8997 - val_loss: 10.9683 - val_accuracy: 0.0565\n","Epoch 6/10\n","43/43 [==============================] - 29s 636ms/step - loss: 2.2845 - accuracy: 0.7875 - val_loss: 339.0048 - val_accuracy: 0.0551\n","Epoch 7/10\n","43/43 [==============================] - 26s 559ms/step - loss: 3.4590 - accuracy: 0.5617 - val_loss: 1377.1833 - val_accuracy: 0.0298\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7a4360886ad0>"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["Data Preprocessing:"],"metadata":{"id":"fCQ7zJSukcr1"}},{"cell_type":"markdown","source":["Ensuring that your data is properly preprocessed. This typically involves normalizing the pixel values to be between 0 and 1 and any other preprocessing techniques such as data augmentation."],"metadata":{"id":"KlqXQ81Eki7F"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Define ImageDataGenerator for preprocessing with data augmentation\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Flow training images in batches of 32 using train_datagen generator\n","train_ds = train_datagen.flow_from_directory(\n","    '/content/drive/MyDrive/Trimmed_AID_dataset/train',\n","    target_size=(256, 256),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","# Flow validation images in batches of 32 using validation_datagen generator\n","validation_ds = validation_datagen.flow_from_directory(\n","    '/content/drive/MyDrive/Trimmed_AID_dataset/val',\n","    target_size=(256, 256),\n","    batch_size=32,\n","    class_mode='categorical'\n",")"],"metadata":{"id":"j2zBziMpgspi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715530451969,"user_tz":-330,"elapsed":834,"user":{"displayName":"Sanjay P","userId":"03374728241233417550"}},"outputId":"8cf8da9e-ba86-48e8-efdb-eccf8eb19ed4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1346 images belonging to 30 classes.\n","Found 672 images belonging to 30 classes.\n"]}]},{"cell_type":"code","source":["# Build ResNet model\n","resnet_model = Sequential()\n","resnet_model.add(ResNet50(include_top=False, weights='imagenet', input_shape=(256, 256, 3)))\n","resnet_model.add(Flatten())\n","resnet_model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001)))  # L2 regularization\n","resnet_model.add(BatchNormalization())  # Batch normalization layer\n","resnet_model.add(Dropout(0.5))  # Dropout layer\n","resnet_model.add(Dense(num_classes, activation='softmax'))\n","\n","\n","# Define callbacks\n","early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)\n","\n","# Compile and fit ResNet model with callbacks\n","resnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","resnet_model.fit(train_ds, epochs=10, validation_data=validation_ds, callbacks=[early_stopping, checkpoint])"],"metadata":{"id":"p7NTd7q9gsnW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715531123690,"user_tz":-330,"elapsed":656211,"user":{"displayName":"Sanjay P","userId":"03374728241233417550"}},"outputId":"041a9059-8d91-4da7-def5-7ba757014301"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","43/43 [==============================] - 83s 1s/step - loss: 4.2399 - accuracy: 0.2437 - val_loss: 295.8046 - val_accuracy: 0.0298\n","Epoch 2/10\n","43/43 [==============================] - 51s 1s/step - loss: 3.8386 - accuracy: 0.3841 - val_loss: 201.3369 - val_accuracy: 0.0298\n","Epoch 3/10\n","43/43 [==============================] - 45s 1s/step - loss: 4.6240 - accuracy: 0.2132 - val_loss: 6299.6890 - val_accuracy: 0.0298\n","Epoch 4/10\n","43/43 [==============================] - 45s 1s/step - loss: 4.3324 - accuracy: 0.2407 - val_loss: 129.7597 - val_accuracy: 0.0298\n","Epoch 5/10\n","43/43 [==============================] - 46s 1s/step - loss: 3.9146 - accuracy: 0.3016 - val_loss: 953.2681 - val_accuracy: 0.0298\n","Epoch 6/10\n","43/43 [==============================] - 50s 1s/step - loss: 3.7039 - accuracy: 0.3299 - val_loss: 157.1633 - val_accuracy: 0.0565\n","Epoch 7/10\n","43/43 [==============================] - 48s 1s/step - loss: 3.3065 - accuracy: 0.3826 - val_loss: 6.3342 - val_accuracy: 0.0298\n","Epoch 8/10\n","43/43 [==============================] - 45s 1s/step - loss: 2.8986 - accuracy: 0.4688 - val_loss: 9.4749 - val_accuracy: 0.0357\n","Epoch 9/10\n","43/43 [==============================] - 45s 1s/step - loss: 2.9438 - accuracy: 0.4443 - val_loss: 14.4384 - val_accuracy: 0.0298\n","Epoch 10/10\n","43/43 [==============================] - 47s 1s/step - loss: 4.2789 - accuracy: 0.1865 - val_loss: 5.3716 - val_accuracy: 0.0134\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7a41fed96110>"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["it seems that the training process is unstable, and the model is not converging effectively. The validation loss and accuracy are fluctuating, and the validation accuracy is quite low.\n","\n","let's try a lower learning rate to see if it helps stabilize the training process and improve convergence. Let's try reducing the learning rate to 0.0001 and see how the model performs"],"metadata":{"id":"FvYWA63-ppjv"}},{"cell_type":"markdown","source":["Learning Rate"],"metadata":{"id":"gwNNcqUMoV4c"}},{"cell_type":"markdown","source":["Lets add some learning rate"],"metadata":{"id":"CYUdLI6ooRz5"}},{"cell_type":"code","source":["from tensorflow.keras.optimizers import Adam"],"metadata":{"id":"5_NTIWdhpG1g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Build ResNet model\n","resnet_model = Sequential()\n","resnet_model.add(ResNet50(include_top=False, weights='imagenet', input_shape=(256, 256, 3)))\n","resnet_model.add(Flatten())\n","resnet_model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001)))  # L2 regularization\n","resnet_model.add(BatchNormalization())  # Batch normalization layer\n","resnet_model.add(Dropout(0.5))  # Dropout layer\n","resnet_model.add(Dense(num_classes, activation='softmax'))\n","\n","\n","# Define callbacks\n","early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)\n","\n","learning_rate = 0.0001\n","\n","# Compile ResNet model with the specified learning rate\n","resnet_model.compile(optimizer=Adam(learning_rate=learning_rate),\n","                     loss='categorical_crossentropy',\n","                     metrics=['accuracy'])\n","\n","# Fit ResNet model with callbacks\n","resnet_model.fit(train_ds, epochs=10,\n","                 validation_data=validation_ds,\n","                 callbacks=[early_stopping, checkpoint])"],"metadata":{"id":"pY1jpCcJIp6J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715532098995,"user_tz":-330,"elapsed":444220,"user":{"displayName":"Sanjay P","userId":"03374728241233417550"}},"outputId":"f0478672-c343-4109-89fd-a875e88bdab1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","43/43 [==============================] - 81s 1s/step - loss: 2.7108 - accuracy: 0.4331 - val_loss: 12.1873 - val_accuracy: 0.0312\n","Epoch 2/10\n","43/43 [==============================] - 46s 1s/step - loss: 1.3396 - accuracy: 0.7437 - val_loss: 11.8698 - val_accuracy: 0.0298\n","Epoch 3/10\n","43/43 [==============================] - 53s 1s/step - loss: 1.0621 - accuracy: 0.8484 - val_loss: 8.8102 - val_accuracy: 0.0461\n","Epoch 4/10\n","43/43 [==============================] - 49s 1s/step - loss: 1.0620 - accuracy: 0.8373 - val_loss: 6.9655 - val_accuracy: 0.0283\n","Epoch 5/10\n","43/43 [==============================] - 52s 1s/step - loss: 0.9160 - accuracy: 0.8923 - val_loss: 7.6049 - val_accuracy: 0.0580\n","Epoch 6/10\n","43/43 [==============================] - 46s 1s/step - loss: 0.8447 - accuracy: 0.9056 - val_loss: 8.7990 - val_accuracy: 0.0432\n","Epoch 7/10\n","43/43 [==============================] - 47s 1s/step - loss: 0.7657 - accuracy: 0.9361 - val_loss: 8.1163 - val_accuracy: 0.0461\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7a40f56f98d0>"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["Fine Tuning"],"metadata":{"id":"UYCFNjdVudNG"}},{"cell_type":"markdown","source":["let's fine-tune the model by unfreezing some layers of the ResNet backbone and allowing them to be updated during training. Here's how you can modify your code to achieve this:"],"metadata":{"id":"KLTTMsPaubUR"}},{"cell_type":"code","source":["from tensorflow.keras.layers import GlobalAveragePooling2D"],"metadata":{"id":"r0qM6Ey9oe8k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load ResNet50 model without the top classification layer\n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n","\n","# Freeze all layers in the base model\n","base_model.trainable = False\n","\n","# Create a new model on top of the ResNet50 backbone\n","inputs = tf.keras.Input(shape=(256, 256, 3))\n","x = base_model(inputs, training=False)\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n","x = BatchNormalization()(x)\n","x = Dropout(0.5)(x)\n","outputs = Dense(num_classes, activation='softmax')(x)\n","fine_tuned_model = tf.keras.Model(inputs, outputs)"],"metadata":{"id":"QkvT5w4Iuhh1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compile the model\n","learning_rate = 0.0001\n","fine_tuned_model.compile(optimizer=Adam(learning_rate=learning_rate),\n","                         loss='categorical_crossentropy',\n","                         metrics=['accuracy'])\n","\n","# Fine-tune the model by training with unfreezed layers\n","history = fine_tuned_model.fit(train_ds, epochs=100,\n","                               validation_data=validation_ds,\n","                               callbacks=[early_stopping, checkpoint])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SR7sPD8Wuli5","executionInfo":{"status":"ok","timestamp":1715533680948,"user_tz":-330,"elapsed":175943,"user":{"displayName":"Sanjay P","userId":"03374728241233417550"}},"outputId":"76b3899c-6b22-4871-97ac-e2647d6408a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","43/43 [==============================] - 50s 1s/step - loss: 2.9820 - accuracy: 0.2028 - val_loss: 3.0521 - val_accuracy: 0.1592\n","Epoch 2/100\n","43/43 [==============================] - 42s 981ms/step - loss: 2.9177 - accuracy: 0.2080 - val_loss: 3.2823 - val_accuracy: 0.1012\n","Epoch 3/100\n","43/43 [==============================] - 40s 938ms/step - loss: 2.8870 - accuracy: 0.2073 - val_loss: 3.2061 - val_accuracy: 0.1801\n","Epoch 4/100\n","43/43 [==============================] - 42s 969ms/step - loss: 2.8603 - accuracy: 0.2385 - val_loss: 3.1195 - val_accuracy: 0.2009\n"]}]},{"cell_type":"code","source":["# Compile the model\n","learning_rate = 0.0001\n","fine_tuned_model.compile(optimizer=Adam(learning_rate=learning_rate),\n","                         loss='categorical_crossentropy',\n","                         metrics=['accuracy'])\n","\n","# Fine-tune the model by training with unfreezed layers\n","history = fine_tuned_model.fit(train_ds, epochs=50,\n","                               validation_data=validation_ds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":651},"id":"IPnDlBd3u0bo","executionInfo":{"status":"error","timestamp":1715534233759,"user_tz":-330,"elapsed":416848,"user":{"displayName":"Sanjay P","userId":"03374728241233417550"}},"outputId":"2d3a7c0a-e754-45cf-b986-a7a7d1d583e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","43/43 [==============================] - 46s 970ms/step - loss: 2.9617 - accuracy: 0.2021 - val_loss: 2.9178 - val_accuracy: 0.2039\n","Epoch 2/50\n","43/43 [==============================] - 41s 946ms/step - loss: 2.9045 - accuracy: 0.2110 - val_loss: 2.9692 - val_accuracy: 0.2083\n","Epoch 3/50\n","43/43 [==============================] - 41s 956ms/step - loss: 2.8701 - accuracy: 0.2281 - val_loss: 3.0277 - val_accuracy: 0.1414\n","Epoch 4/50\n","43/43 [==============================] - 41s 959ms/step - loss: 2.8619 - accuracy: 0.2155 - val_loss: 3.1708 - val_accuracy: 0.1682\n","Epoch 5/50\n","43/43 [==============================] - 41s 954ms/step - loss: 2.8543 - accuracy: 0.2080 - val_loss: 3.2324 - val_accuracy: 0.1890\n","Epoch 6/50\n","43/43 [==============================] - 42s 980ms/step - loss: 2.7755 - accuracy: 0.2281 - val_loss: 3.3116 - val_accuracy: 0.1518\n","Epoch 7/50\n","43/43 [==============================] - 41s 952ms/step - loss: 2.7662 - accuracy: 0.2370 - val_loss: 3.8683 - val_accuracy: 0.1711\n","Epoch 8/50\n","43/43 [==============================] - 41s 948ms/step - loss: 2.7284 - accuracy: 0.2266 - val_loss: 3.6286 - val_accuracy: 0.1384\n","Epoch 9/50\n","43/43 [==============================] - 41s 958ms/step - loss: 2.7430 - accuracy: 0.2467 - val_loss: 3.2767 - val_accuracy: 0.1905\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-e31624c4de36>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Fine-tune the model by training with unfreezed layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m history = fine_tuned_model.fit(train_ds, epochs=50, \n\u001b[0m\u001b[1;32m      9\u001b[0m                                validation_data=validation_ds)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1793\u001b[0m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1795\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1796\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2701\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m         \"\"\"Resets the state of all the metrics in the model.\n\u001b[1;32m   2705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"24W6HpzxyKFG"},"execution_count":null,"outputs":[]}]}